{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input():\n",
    "    count = 0\n",
    "    with open('adult-corpus.txt', 'w', encoding = 'utf-8') as outfile:\n",
    "        walk_dir = 'corpora/'\n",
    "        for root, subdirs, files in os.walk(walk_dir):\n",
    "            print('--\\nroot = ' + root)\n",
    "            list_file_path = os.path.join(root, 'my-directory-list.txt')\n",
    "            print('list_file_path = ' + list_file_path)\n",
    "            for filename in files:\n",
    "                file_path = os.path.join(root, filename)\n",
    "                print('\\t- file %s (full path: %s)' % (filename, file_path))\n",
    "                if '.cha' in file_path:\n",
    "                    with open(file_path, 'r', encoding = 'utf-8') as infile:\n",
    "                        inlist = infile.read().splitlines()\n",
    "                        for i in range(5):\n",
    "                            inlist = (remove_returns(inlist))\n",
    "                        print (len(inlist))\n",
    "                        for i in range((len(inlist)) -1):\n",
    "                            if (inlist[i][0] == '*'\n",
    "                                    and inlist[i].split()[0] != '*CHI:'\n",
    "                                    and inlist[i+1].split()[0] == '%mor:'):\n",
    "                                outfile.write(inlist[i] + '\\n')\n",
    "                                outfile.write(inlist[i+1] + '\\n')\n",
    "                            #outfile.write(item + '\\n')\n",
    "                            #outfile.write('\\n')\n",
    "                    count +=1\n",
    "    print(count)\n",
    "\n",
    "def remove_returns(inlist):\n",
    "    outlist = []\n",
    "    for i in range(len(inlist)-1):\n",
    "        if (inlist[i][0] in ['*', '%', '&']\n",
    "                and inlist[i+1][0] not in ['*', '%', '&']):\n",
    "            #print('i', inlist[i])\n",
    "            #print('i+1', inlist[i+1])\n",
    "            newline = copy.deepcopy(inlist[i]) + copy.deepcopy(inlist[i+1])\n",
    "            #print('new', newline)\n",
    "            inlist[i] = newline\n",
    "            inlist[i+1] = '<<<REMOVE>>>>'\n",
    "    while '<<<REMOVE>>>>' in inlist:\n",
    "        inlist.remove('<<<REMOVE>>>>')\n",
    "    return inlist  \n",
    "\n",
    "def filter():\n",
    "    with open('adult-corpus.txt', 'r', encoding = 'utf-8') as infile:\n",
    "        inlist = infile.read().splitlines()\n",
    "    print(len(inlist))\n",
    "    print(inlist[0])\n",
    "    print(inlist[1])\n",
    "    with open('adult-corpus-filt-wmor.txt', 'w', encoding = 'utf-8') as outfile:\n",
    "        for line in inlist:\n",
    "            #print(line)\n",
    "            line = filter_line(line)\n",
    "            line = remove_bracketed_items(line)\n",
    "            #print(line)\n",
    "            line = ' '.join(line)\n",
    "            if ('+/' not in line\n",
    "                    and '[//' not in line\n",
    "                    and '+.' not in line\n",
    "                    and '+/' not in line\n",
    "                    and '+\"/' not in line\n",
    "                    and '>' not in line\n",
    "                    and '<' not in line\n",
    "            ):\n",
    "                outfile.write(line + '\\n')\n",
    "    print('done')\n",
    "\n",
    "def remove_bracketed_items(line):\n",
    "    #line = line.split()\n",
    "    #print(line[-3:])\n",
    "    if line[-3:] == ['+', '[+', 'IIN]']:\n",
    "        line = line[:-3]\n",
    "    if line[-3:] == ['+', '[+', 'IN]']:\n",
    "        line = line[:-3]\n",
    "    if line[-2:] == ['+[+', 'IN]']:\n",
    "        line = line[:-2]\n",
    "    for i in range(len(line)):\n",
    "        #print(line[i][-2:])\n",
    "        if line[i][-2:] == '[]':\n",
    "            line[i] = line[i][:-2]\n",
    "    return(line)\n",
    "\n",
    "global a_line\n",
    "def filter_line(line):\n",
    "    global a_line\n",
    "    a_line = line\n",
    "    line = line.split()\n",
    "    #print(line[-2:])\n",
    "    if '\u0015' in line[-1]:\n",
    "        line = line[0:-1]\n",
    "    if line[-1] in ['(1.)', '(2.)', '(3.)', '(4.)', '(5.)', '(6.)', '(7.)']:\n",
    "        line = line[0:-1]\n",
    "    if line[-2] in ['(1.)', '(2.)', '(3.)', '(4.)', '(5.)', '(6.)', '(7.)', '(8.)', '(9.)', '(10.)',\n",
    "                    '(11.)', '(12.)', '(13.)', '(14.)', '(15.)', '(16.)', '(17.)', '(18.)', '(19.)']:\n",
    "        line = line[0:-2] + [line[-1]]\n",
    "    if (len(line) > 2\n",
    "            and line[-2] in ['.', '?', '!']):\n",
    "        print(line)\n",
    "        line = line[0:-1]\n",
    "    for j in range(2):\n",
    "        if (line[-2] == '[+'\n",
    "                and line[-1] in ['PI]', 'Pi]', 'R]', 'SR]', 'RES]', 'MLR]', 'IMIT]', 'IN]', 'I]', 'dia]']):\n",
    "            line = line[:-2]\n",
    "    if (line[-2] == '.[+'\n",
    "            and line[-1] in ['PI]', 'Pi]', 'R]', 'SR]', 'RES]', 'MLR]', 'IMIT]', 'IN]', 'I]', 'dia]']):\n",
    "        line = line[:-2] + ['.']\n",
    "    for j in range(10):\n",
    "        for i in range(len(line)):\n",
    "            if line[i] in ['[?]', '[*]', '[!!]', '[!]']:\n",
    "                #print(i)\n",
    "                line = line[0:i] + line[i+1:]\n",
    "                break\n",
    "    for j in range(10):\n",
    "        start, end = 0,0\n",
    "        for i in range(len(line)):\n",
    "            if ('[:' in line[i]\n",
    "                    or '[%' in line[i]\n",
    "                    or '[x' in line[i]\n",
    "                    or '[=' in line[i]\n",
    "                    or '[^' in line[i]\n",
    "                    or '[*' in line[i]\n",
    "                    or '[+' in line[i]\n",
    "                    or ' [:' in line[i]):\n",
    "                start = i\n",
    "            if ']' in line[i]:\n",
    "                end = i\n",
    "        if (start > 0\n",
    "                and end > start):\n",
    "            #print(line)\n",
    "            line = line[0:start] + line[end+1: len(line)]\n",
    "            #print('new', line)\n",
    "    for j in range(5):\n",
    "        for i in range(len(line)):\n",
    "            if line[i] == '[/]':\n",
    "                #print(line)\n",
    "                line=line[0:i-1] + line[i+1:len(line)]\n",
    "                #print('new', line)\n",
    "                break\n",
    "        for item in line:\n",
    "            if (item in ['.', ',', '!', '?', '(.)', '„', '‡', '&=laughs', '&=laugh', '&=laughing', '&=cough', '&=whispers',\n",
    "                    '&=whistle', '&=hums', '&=whistles', '&=roars', '&=squeals', '+\"', '+\".', '+\"/','[/]']\n",
    "                or '&=' in item):\n",
    "                line.remove(item)\n",
    "    for item in line:\n",
    "        if item == '+\"':\n",
    "            print('yes')\n",
    "            line.remove(item)\n",
    "    for i in range(len(line)):\n",
    "        line[i] = stripstring(line[i])\n",
    "    return(line)\n",
    "\n",
    "def stripstring(string):\n",
    "    outstring = ''\n",
    "    for item in string:\n",
    "        if item not in ['(', ')', '?','!', ',', '.']:\n",
    "            outstring = outstring + item\n",
    "    return outstring\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_input()\n",
    "filter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!grep -v \"%mor\" adult-corpus-filt-wmor.txt | cut -d\":\"  -f2 | sed 's/^ //' > adult-corpus-filt1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = SequenceTagger.load('flair/pos-english')\n",
    "def tag():\n",
    "    with open('adult-corpus-filt1-flair.txt', 'w', encoding='utf-8') as outfile:\n",
    "        with open('adult-corpus-filt1.txt', 'r', encoding = 'utf-8') as infile:\n",
    "            #inlist = infile.read().splitlines()\n",
    "        #inlist = inlist[0:100]\n",
    "            count = 0\n",
    "        #print(len(inlist))\n",
    "        #print(inlist[411468])\n",
    "            while True:\n",
    "\n",
    "                # Get next line from file\n",
    "                line=infile.readline()\n",
    "\n",
    "            # if line is empty\n",
    "            # end of file is reached\n",
    "                if not line:\n",
    "                    break\n",
    "            #print(\"Line{}: {}\".format(count,line.strip()))\n",
    "            #for line in inlist:\n",
    "                if len(line) > 0:\n",
    "                    #    (line[0][0] == '*'\n",
    "                    #and line[0] != '*CHI:'):\n",
    "                    count +=1\n",
    "                    if count % 10000 == 0:\n",
    "                        print(count)\n",
    "                    line = line.split()\n",
    "                    #print(line)\n",
    "                    #sentence = Sentence(line[1:])\n",
    "                    sentence = Sentence(line)\n",
    "                    tagger.predict(sentence)\n",
    "                    labels = sentence.get_labels('pos')\n",
    "                    #print(labels)\n",
    "                    #for label in labels:\n",
    "                    #    print(label.value)\n",
    "                    #print(sentences)\n",
    "                    outfile.write('line: ' + ' '.join(line) + '\\n')\n",
    "                    outfile.write('tags: ')\n",
    "                    for i in range(len(line)):\n",
    "                        outfile.write(labels[i].value + ' ')\n",
    "                    outfile.write('\\n')\n",
    "    infile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morphemize():\n",
    "    with open('adult-corpus-filt1-flair.txt', 'r', encoding = 'utf-8') as infile:\n",
    "        inlist =infile.read().splitlines()\n",
    "        print(len(inlist))\n",
    "        print(inlist[0])\n",
    "        verb_dict = {}\n",
    "        with open('adult-corpus-filt1-marked-flair+tag.txt', 'w', encoding = 'utf-8') as outfile:\n",
    "            for i in range(len(inlist)-1):\n",
    "                if i % 1000000 ==0:\n",
    "                    print(i)\n",
    "                if (len(inlist[i]) > 0\n",
    "                    and len(inlist[i+1]) >0\n",
    "                    and i % 2 == 0):\n",
    "                    #and len(inlist[i]) == len(inlist[i+1])):\n",
    "                    #and inlist[i][0].islower()\n",
    "                    #and inlist[i+1][0].isupper()):\n",
    "                        line = inlist[i].split()[1:]\n",
    "                        labels = inlist[i+1].split()[1:]\n",
    "                        outline = []\n",
    "                        #print(line)\n",
    "                        #print(labels)\n",
    "                        for i in range(len(labels)):\n",
    "                            #print(i)\n",
    "                            while (len(line[i]) > 1\n",
    "                                and line[i][-1] in ['.', ',', '!', '?', '-']):\n",
    "                                line[i] = line[i][:-1]\n",
    "                            if (labels[i] == 'VBZ'\n",
    "                                and \"'\" not in line[i]\n",
    "                                and line[i].lower() not in ['is', 'does', 'has']):\n",
    "                                    if line[i] in ['goes', 'undergoes', 'echoes', 'focuses', 'passes', 'encompasses', 'possesses', 'expresses']:\n",
    "                                            outline = outline + [line[i][:-2] + '-3S']\n",
    "                                    elif (len(line[i]) >3\n",
    "                                        and line[i][-3:] == 'hes'\n",
    "                                        and line[i] not in 'breathes'):\n",
    "                                            outline = outline +[line[i][:-2] + '-3S']\n",
    "                                    elif (len(line[i]) >4\n",
    "                                        and line[i][-4:] == 'sses'):\n",
    "                                            outline = outline +[line[i][:-2] + '-3S']\n",
    "                                    elif line[i] in ['varies', 'implies', 'applies', 'relies', 'tries', 'occupies', 'studies', 'supplies', 'denies', 'flies', 'embodies', 'replies', 'marries','empties', 'cries', 'carries', 'accompanies', 'complies', 'multiplies', 'dries', 'worries', 'copies', 'buries', 'queries', 'levies']:\n",
    "                                        outline = outline +[line[i][:-3] + 'y' + '-3S']\n",
    "                                    elif (len(line[i]) > 3\n",
    "                                        and(line[i][-4:] == 'fies')):\n",
    "                                        outline = outline +[line[i][:-3] + 'y' + '-3S']\n",
    "                                    elif len(line[i]) > 1:\n",
    "                                        outline = outline + [line[i][:-1] + '-3S']\n",
    "                                        if  line[i][-2:] == 'es':\n",
    "                                            #print(line[i])\n",
    "                                            if line[i] in verb_dict:\n",
    "                                                verb_dict[line[i]] +=1\n",
    "                                            else:\n",
    "                                                verb_dict[line[i]] =1\n",
    "                            elif (labels[i] in ['VBP', 'VB']\n",
    "                                and \"'\" not in line[i]\n",
    "                                and line[i] not in ['*MOT:']\n",
    "                                  and line[i].lower() not in ['am', 'are', 'do', 'be', 'have']):\n",
    "                                    outline = outline + [line[i] + '-BARE']\n",
    "                            else:\n",
    "                                outline.append(line[i])\n",
    "                        #for item in labels:\n",
    "                        #    print('label', item, item.value)\n",
    "                        #print(line, outline)\n",
    "                        outfile.write('line: ' + ' '.join(outline) + '\\n')\n",
    "                        outfile.write('tags: ' + ' '.join(labels) + '\\n')\n",
    "        outbin = []\n",
    "        #for item in verb_dict:\n",
    "        #    outbin.append([item, verb_dict[item]])\n",
    "        #outbin = sorted(outbin, key=lambda x: x[1], reverse=True)\n",
    "        #for item in outbin:\n",
    "        #    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphemize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits():\n",
    "    global model_run\n",
    "    out_dir = 'training-splits/'\n",
    "    voc = 10\n",
    "    for max_len in[3,4,5,6,8,10]:\n",
    "        for model_run in [1,2,3,4,5]:\n",
    "            print('ml, mr', max_len, model_run)\n",
    "            train_seqs, test_seqs, token2int = get_cds(max_len, voc)\n",
    "            print(len(train_seqs), len(test_seqs))\n",
    "            with open(out_dir + 'adults-lm-max' + str(max_len) + '-split' + str(model_run) + '-train.txt', 'w', encoding = 'utf-8') as outfile:\n",
    "                for item in train_seqs:\n",
    "                    #print(item)\n",
    "                    outfile.write('line: ' + ' '.join(item[0]) + '\\n')\n",
    "                    outfile. write('tags: ' + ' '.join(item[1]) + '\\n')\n",
    "            outfile.close()\n",
    "            with open(out_dir + 'adults-lm-max' + str(max_len) + '-split' + str(model_run) + '-test.txt', 'w', encoding = 'utf-8') as outfile:\n",
    "                for item in test_seqs:\n",
    "                    outfile.write('line: ' + ' '.join(item[0]) + '\\n')\n",
    "                    outfile. write('tags: ' + ' '.join(item[1]) + '\\n')\n",
    "            outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cds(max_len = 5, voc =0):\n",
    "    global word_dict, model_run\n",
    "    word_dict, token2int = {}, {}\n",
    "    temp_list, train_list,test_list = [],[],[]\n",
    "    seq_list_all = []\n",
    "    templist, line_list,train_bin, test_bin = [], [], [], []\n",
    "    count1,count2, third_count =0,0,0\n",
    "    lcount = 0\n",
    "    infile = 'adult-corpus-filt1-marked-flair+tag.txt'\n",
    "    #infile = 'subtitles-en-marked-flair+tag.txt'\n",
    "    #infile = 'subt-sample-wflair.txt'\n",
    "    indir = ''\n",
    "    print('input file ', infile)\n",
    "    print('seq_length =', max_len)\n",
    "    print('voc =', voc)\n",
    "    with open(indir + infile, 'r', encoding='utf-8') as infile:\n",
    "        inlist = infile.read().splitlines()\n",
    "    ##inlist = inlist[0:1000]\n",
    "    print(len(inlist))\n",
    "    count,outline = 0, ''\n",
    "    word_dict['<eos>'] = 100000\n",
    "    word_dict['<pad>'] = 100000\n",
    "    word_dict['-BARE'] = 100000\n",
    "    word_dict['-3S'] = 100000\n",
    "    print(word_dict['-BARE'])\n",
    "    for line in inlist:\n",
    "        line = line.split()\n",
    "        for word in line:\n",
    "            if '-BARE' in word:\n",
    "                word = word[0:-5]\n",
    "            if '-3S' in word:\n",
    "                word = word[0:-3]\n",
    "            if word not in ['-3S', '-BARE']:\n",
    "                word = word.lower()\n",
    "            if word in word_dict:\n",
    "                word_dict[word] += 1\n",
    "            else:\n",
    "                word_dict[word] = 1\n",
    "    print('total word count', len(word_dict))\n",
    "    for i in range(len(inlist)):\n",
    "        lcount +=1\n",
    "        #if lcount == 10000:\n",
    "        #    break\n",
    "        if inlist[i].split()[0] == 'line:':\n",
    "            line,tags = split_line(inlist[i].split()[1:], inlist[i+1].split()[1:])\n",
    "            #print(lcount, line,tags)\n",
    "            for j in range(len(line)):\n",
    "                index = j + 1\n",
    "                if j < max_len:\n",
    "                    temp_list.append([line[0:index], tags[0:index]])\n",
    "                else:\n",
    "                    temp_list.append([line[index-max_len:index], tags[index-max_len:index]])\n",
    "    print('done')\n",
    "    cnt = 0\n",
    "    if '<pad>' not in token2int:\n",
    "        token2int['<pad>'] = cnt\n",
    "        cnt +=1\n",
    "    for line in temp_list:\n",
    "        #print(line)\n",
    "        for i in range(len(line[0])):\n",
    "            #if line[0][i] == 'greeting':\n",
    "            #    print(line[0][i], word_dict[line[0][i]])\n",
    "            if word_dict[line[0][i]] < voc:\n",
    "                line[0][i] = '<unk>'\n",
    "\n",
    "            if line[0][i] not in token2int:\n",
    "                token2int[line[0][i]] = cnt\n",
    "                cnt += 1\n",
    "            # if '<pad>' not in token2int:\n",
    "            #    token2int['<pad>'] = cnt\n",
    "        if line[0][-1] in ['-BARE', '-3S']:\n",
    "            if  random.randint(1,10) < 3:\n",
    "                #seq_list_all.append(line)\n",
    "                test_bin.append(line)\n",
    "                count1 +=1\n",
    "            else:\n",
    "                #seq_list_all.append(line)\n",
    "                train_bin.append(line)\n",
    "                count2 +=1\n",
    "            if line[0][-1] == '-3S':\n",
    "                third_count += 1\n",
    "        else:\n",
    "            #seq_list_all.append(line)\n",
    "            train_bin.append(line)\n",
    "    #out_dir = 'training-splits/'\n",
    "    #write_list_to_json(train_bin, out+dir + 'adults-lm-max' + str(max_len) + 'split' + str(model_run) + '-train.txt')\n",
    "    #write_list_to_json(test_bin, out+dir + 'adults-lm-max' + str(max_len) + 'split' + str(model_run) + '-test.txt')\n",
    "    #with open('adults-marked1-full-voc10.txt', 'w', encoding = 'utf-8') as outfile:\n",
    "    #    for line in line_list:\n",
    "    #        outfile.write(line + '\\n')\n",
    "    print(count1, count2)\n",
    "    print('third_count', third_count)\n",
    "    print(train_bin[0])\n",
    "    print(test_bin[0])\n",
    "    #train_bin = train_bin[0:10000]\n",
    "    #train_bin, test_bin =[],[]\n",
    "    #train_bin, test_bin = read_split(model_run, max_len)\n",
    "    print(len(train_bin), len(test_bin))\n",
    "    print(train_bin[0])\n",
    "    print(test_bin[0])\n",
    "    return train_bin,test_bin, token2int\n",
    "\n",
    "\n",
    "def split_line(line, tags):\n",
    "    outline, outtags = [], []\n",
    "    for i in range(len(line)):\n",
    "        if '-BARE' in line[i]:\n",
    "            outline.append(line[i][0:-5].lower())\n",
    "            outline.append('-BARE')\n",
    "            outtags.append(tags[i])\n",
    "            outtags.append('-BARE')\n",
    "        elif '-3S' in line[i]:\n",
    "            outline.append(line[i][0:-3].lower())\n",
    "            outline.append('-3S')\n",
    "            outtags.append(tags[i])\n",
    "            outtags.append('-3S')\n",
    "        else:\n",
    "            outline.append(line[i].lower())\n",
    "            outtags.append(tags[i])\n",
    "    return outline, outtags\n",
    "\n",
    "\n",
    "def read_split(run, my_len):\n",
    "    train_seqs, test_seqs = [],[]\n",
    "    print('reading split: ', run, 'length = ', my_len)\n",
    "    in_dir = 'training-splits/'\n",
    "    print(in_dir + 'adults-lm-max' + str(my_len) + '-split' + str(run) + '-train.txt')\n",
    "    with open(in_dir + 'adults-lm-max' + str(my_len) + '-split' + str(run) + '-train.txt', 'r', encoding = 'utf-8') as infile:\n",
    "        inlist = infile.read().splitlines()\n",
    "    print(inlist[0])\n",
    "    print(inlist[1])\n",
    "    print('done')\n",
    "    #print(len(inlist))\n",
    "    print(len(inlist))\n",
    "    for i in range(len(inlist)):\n",
    "        if inlist[i].split()[0] == 'line:':\n",
    "            train_seqs.append([inlist[i].split()[1:], inlist[i+1].split()[1:]])\n",
    "    with open(in_dir + 'adults-lm-max' + str(my_len) + '-split' + str(run) + '-test.txt', 'r', encoding = 'utf-8') as infile:\n",
    "        inlist = infile.read().splitlines()\n",
    "    for i in range(len(inlist)):\n",
    "        if inlist[i].split()[0] == 'line:':\n",
    "            test_seqs.append([inlist[i].split()[1:], inlist[i + 1].split()[1:]])\n",
    "    return train_seqs, test_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "get_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_seqs, test_seqs = [],[]\n",
    "#train_bin, test_bin =[],[]\n",
    "#word_dict = {}\n",
    "\n",
    "#train_bin, test_bin =[],[]\n",
    "#train_seqs, test_seqs = [],[]\n",
    "#global seq_dict\n",
    "\n",
    "#voc = 10\n",
    "\n",
    "#global token2int, int2token, vocab_size\n",
    "#token2int, int2token = {},{}\n",
    "\n",
    "#outbin = []\n",
    "#global net\n",
    "#global max_len, model_run\n",
    "#for max_len in [5]:\n",
    "#    outbin = []\n",
    "#    #print(x_int[70], y_int[70])\n",
    "#    for i in range(1):\n",
    "#        model_run = i+1\n",
    "#        train_seqs,test_seqs, token2int = get_cds(max_len,voc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
